{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Borden Dataset into HuggingFace Dataset Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = '/data2/eranario/data/yolo_grl_data/BordenNight/Real/train'\n",
    "path_to_valid = '/data2/eranario/data/yolo_grl_data/BordenNight/Real/valid'\n",
    "path_to_test = '/data2/eranario/data/yolo_grl_data/BordenNight/Real/test'\n",
    "\n",
    "all_source_paths = {'train': path_to_train, 'valid': path_to_valid, 'test': path_to_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_target = '/data2/eranario/data/Active-Learning-Datasets/Borden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in all_source_paths.items():\n",
    "    source = os.path.join(value, 'images')\n",
    "    target = os.path.join(path_to_target, key)\n",
    "\n",
    "    # copy source to target\n",
    "    os.system('cp -r ' + source + ' ' + target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metadata file from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yolo_to_metadata(label_dir, output_file, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Convert YOLO label files into a single metadata JSON file suitable for HuggingFace Object Detection Dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - label_dir: Directory containing the YOLO label files.\n",
    "    - output_file: Path where the single metadata JSON file will be saved.\n",
    "    - image_width: Width of the images corresponding to the label files.\n",
    "    - image_height: Height of the images corresponding to the label files.\n",
    "    \"\"\"\n",
    "    def yolo_to_bbox(yolo_data, img_width, img_height):\n",
    "        x_center, y_center, width, height = yolo_data\n",
    "        x_min = (x_center - width / 2) * img_width\n",
    "        y_min = (y_center - height / 2) * img_height\n",
    "        bbox_width = width * img_width\n",
    "        bbox_height = height * img_height\n",
    "        return [x_min, y_min, bbox_width, bbox_height]\n",
    "\n",
    "    metadata_list = []\n",
    "\n",
    "    for label_id, label_file in enumerate(os.listdir(label_dir)):\n",
    "        if label_file.endswith('.txt'):\n",
    "            with open(os.path.join(label_dir, label_file), 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            bboxes = []\n",
    "            categories = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                category_id = int(parts[0])\n",
    "                bbox = yolo_to_bbox(list(map(float, parts[1:])), image_width, image_height)\n",
    "                bboxes.append(bbox)\n",
    "                categories.append(category_id)\n",
    "\n",
    "            metadata = {\n",
    "                \"image_id\": label_id,\n",
    "                \"file_name\": label_file.replace('.txt', '.jpg'),\n",
    "                \"width\": image_width,\n",
    "                \"height\": image_height,\n",
    "                \"objects\": {\n",
    "                    \"bbox\": bboxes,\n",
    "                    \"categories\": categories\n",
    "                }\n",
    "            }\n",
    "\n",
    "            metadata_list.append(metadata)\n",
    "\n",
    "    # Write all metadata entries to a single JSON file\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        for entry in metadata_list:\n",
    "            json.dump(entry, json_file)\n",
    "            json_file.write('\\n')\n",
    "\n",
    "    print(f\"Conversion completed. Metadata saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example image width: 720, height: 1280\n"
     ]
    }
   ],
   "source": [
    "# get example image width and height\n",
    "example_image = os.path.join(path_to_target, 'train', os.listdir(os.path.join(path_to_target, 'train'))[0])\n",
    "example_image_width, example_image_height = os.popen(f'identify -format \"%w %h\" {example_image}').read().split()\n",
    "print(f\"Example image width: {example_image_width}, height: {example_image_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. Metadata saved to /data2/eranario/data/Active-Learning-Datasets/Borden/train/metadata.jsonl\n",
      "Conversion completed. Metadata saved to /data2/eranario/data/Active-Learning-Datasets/Borden/valid/metadata.jsonl\n",
      "Conversion completed. Metadata saved to /data2/eranario/data/Active-Learning-Datasets/Borden/test/metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "for key, value in all_source_paths.items():\n",
    "    label_dir = os.path.join(value, 'labels')\n",
    "    output_dir = os.path.join(path_to_target, key, 'metadata.jsonl')\n",
    "    convert_yolo_to_metadata(label_dir, output_dir, int(example_image_width), int(example_image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Custom HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hf_train = os.path.join(path_to_target, 'train')\n",
    "path_to_hf_valid = os.path.join(path_to_target, 'valid')\n",
    "path_to_hf_test = os.path.join(path_to_target, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data2/eranario/data/Active-Learning-Datasets/Borden/train'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_hf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 99/99 [00:00<00:00, 184549.38files/s]\n",
      "Generating train split: 98 examples [00:00, 2275.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = load_dataset('imagefolder', data_dir=path_to_hf_train, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'image_id', 'width', 'height', 'objects'],\n",
       "    num_rows: 98\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
