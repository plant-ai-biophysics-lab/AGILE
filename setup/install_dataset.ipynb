{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agml\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_yolo(coco_json_path, images_dir, output_dir):\n",
    "    # Load COCO annotations\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    images = coco_data[\"images\"]\n",
    "    annotations = coco_data[\"annotations\"]\n",
    "    categories = coco_data[\"categories\"]\n",
    "\n",
    "    # Mapping image_id to file_name\n",
    "    img_id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in images}\n",
    "\n",
    "    # Mapping category_id to YOLO class index\n",
    "    if len(categories) == 1:\n",
    "        cat_id_to_yolo_id = {categories[0][\"id\"]: 0}\n",
    "    else:\n",
    "        cat_id_to_yolo_id = {cat[\"id\"]: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "    # Organizing annotations by image_id\n",
    "    img_annotations = {img[\"id\"]: [] for img in images}\n",
    "    for ann in annotations:\n",
    "        img_annotations[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    # Shuffle images for random split\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Define split sizes\n",
    "    total = len(images)\n",
    "    train_size = int(0.6 * total)\n",
    "    val_size = int(0.15 * total)\n",
    "    \n",
    "    train_imgs = images[:train_size]\n",
    "    val_imgs = images[train_size:train_size + val_size]\n",
    "    test_imgs = images[train_size + val_size:]\n",
    "\n",
    "    # Define dataset splits\n",
    "    splits = {\n",
    "        \"train\": train_imgs,\n",
    "        \"val\": val_imgs,\n",
    "        \"test\": test_imgs\n",
    "    }\n",
    "\n",
    "    # Create output directories\n",
    "    for split in splits.keys():\n",
    "        os.makedirs(os.path.join(output_dir, split, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "    # Convert annotations and copy images\n",
    "    for split, img_list in splits.items():\n",
    "        for img in tqdm(img_list, desc=f\"Processing {split}\"):\n",
    "            img_id = img[\"id\"]\n",
    "            file_name = img[\"file_name\"]\n",
    "            img_path = os.path.join(images_dir, file_name)\n",
    "            output_img_path = os.path.join(output_dir, split, \"images\", file_name)\n",
    "\n",
    "            # Copy image to appropriate split folder\n",
    "            if os.path.exists(img_path):\n",
    "                shutil.copy(img_path, output_img_path)\n",
    "\n",
    "            # Create YOLO label file\n",
    "            label_path = os.path.join(output_dir, split, \"labels\", file_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "            with open(label_path, \"w\") as label_file:\n",
    "                for ann in img_annotations.get(img_id, []):\n",
    "                    x, y, w, h = ann[\"bbox\"]\n",
    "                    img_w, img_h = img[\"width\"], img[\"height\"]\n",
    "\n",
    "                    # Convert to YOLO format (normalized x_center, y_center, width, height)\n",
    "                    x_center = (x + w / 2) / img_w\n",
    "                    y_center = (y + h / 2) / img_h\n",
    "                    w /= img_w\n",
    "                    h /= img_h\n",
    "\n",
    "                    # For a single-class dataset, always assign class 0.\n",
    "                    if len(categories) == 1:\n",
    "                        yolo_class = 0\n",
    "                    else:\n",
    "                        category_id = ann[\"category_id\"]\n",
    "                        if category_id not in cat_id_to_yolo_id:\n",
    "                            print(f\"Warning: category id {category_id} not found in mapping. Skipping annotation.\")\n",
    "                            continue\n",
    "                        yolo_class = cat_id_to_yolo_id[category_id]\n",
    "\n",
    "                    label_file.write(f\"{yolo_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    print(\"Dataset conversion and splitting completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Domain (Synthetic Grape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading grape_detection_syntheticday (size = 48.6 MB): 48635904it [00:01, 41610906.69it/s]                              ape_detection_syntheticday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AgML Download]: Extracting files for grape_detection_syntheticday... Done!\n",
      "\n",
      "================================================================================\n",
      "You have just downloaded \u001b[1mgrape_detection_syntheticday\u001b[0m.\n",
      "\n",
      "This dataset has \u001b[1mno license\u001b[0m.\n",
      "\n",
      "When using this dataset, please cite the following:\n",
      "\n",
      "@ARTICLE{10.3389/fpls.2019.01185,\n",
      "  \n",
      "AUTHOR={Bailey, Brian N.},   \n",
      "\t \n",
      "TITLE={Helios: A Scalable 3D Plant and Environmental Biophysical Modeling Framework},      \n",
      "\t\n",
      "JOURNAL={Frontiers in Plant Science},      \n",
      "\t\n",
      "VOLUME={10},      \n",
      "\t\n",
      "YEAR={2019},      \n",
      "\t  \n",
      "URL={https://www.frontiersin.org/article/10.3389/fpls.2019.01185},       \n",
      "\t\n",
      "DOI={10.3389/fpls.2019.01185},      \n",
      "\t\n",
      "ISSN={1664-462X},   \n",
      "   \n",
      "ABSTRACT={This article presents an overview of Helios, a new three-dimensional (3D) plant and environmental modeling framework. Helios is a model coupling framework designed to provide maximum flexibility in integrating and running arbitrary 3D environmental system models. Users interact with Helios through a well-documented open-source C++ API. Version 1.0 comes with model plug-ins for radiation transport, the surface energy balance, stomatal conductance, photosynthesis, solar position, and procedural tree generation. Additional plug-ins are also available for visualizing model geometry and data and for processing and integrating LiDAR scanning data. Many of the plug-ins perform calculations on the graphics processing unit, which allows for efficient simulation of very large domains with high detail. An example modeling study is presented in which leaf-level heterogeneity in water usage and photosynthesis of an orchard is examined to understand how this leaf-scale variability contributes to whole-tree and -canopy fluxes.}\n",
      "}\n",
      "\n",
      "You can find additional information about this dataset at:\n",
      "N/A\n",
      "\n",
      "This message will \u001b[1mnot\u001b[0m be automatically shown\n",
      "again. To view this message again, in an AgMLDataLoader\n",
      "run `loader.info.citation_summary()`. Otherwise, you\n",
      "can use `agml.data.source(<name>).citation_summary().`\n",
      "\n",
      "You can find your dataset at /group/jmearlesgrp/scratch/eranario/AGILE/datasets/grape_detection_syntheticday.\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AgMLDataLoader: (dataset=grape_detection_syntheticday, task=object_detection, images=448) at 0xa6f80c55420>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install dataset\n",
    "agml.data.AgMLDataLoader(\n",
    "    'grape_detection_syntheticday', \n",
    "    dataset_path='../datasets/grape_detection_syntheticday'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|          | 0/268 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 268/268 [00:01<00:00, 136.11it/s]\n",
      "Processing val: 100%|██████████| 67/67 [00:00<00:00, 130.62it/s]\n",
      "Processing test: 100%|██████████| 113/113 [00:00<00:00, 141.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion and splitting completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coco_to_yolo(\n",
    "    coco_json_path=\"../datasets/grape_detection_syntheticday/annotations.json\", \n",
    "    images_dir=\"../datasets/grape_detection_syntheticday/images\",\n",
    "    output_dir=\"../datasets/grape_detection_syntheticday/reformatted\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Domain (Real Grape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading grape_detection_californiaday (size = 359.6 MB): 359653376it [00:07, 45528804.61it/s]                               _detection_californiaday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AgML Download]: Extracting files for grape_detection_californiaday... Done!\n",
      "\n",
      "================================================================================\n",
      "You have just downloaded \u001b[1mgrape_detection_californiaday\u001b[0m.\n",
      "\n",
      "This dataset has \u001b[1mno license\u001b[0m.\n",
      "\n",
      "When using this dataset, please cite the following:\n",
      "\n",
      "@misc{GrapeDay,\n",
      "  author    = {Plant AI and Biophysics Lab},\n",
      "  title     = {Grape Detection 2019 Day},\n",
      "  year      = {2019},\n",
      "  url       = {https://github.com/plant-ai-biophysics-lab/AgML} \n",
      " \n",
      "\n",
      "You can find additional information about this dataset at:\n",
      "\n",
      "\n",
      "This message will \u001b[1mnot\u001b[0m be automatically shown\n",
      "again. To view this message again, in an AgMLDataLoader\n",
      "run `loader.info.citation_summary()`. Otherwise, you\n",
      "can use `agml.data.source(<name>).citation_summary().`\n",
      "\n",
      "You can find your dataset at /group/jmearlesgrp/scratch/eranario/AGILE/datasets/grape_detection_californiaday.\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AgMLDataLoader: (dataset=grape_detection_californiaday, task=object_detection, images=126) at 0xa6f7b55b790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install dataset\n",
    "agml.data.AgMLDataLoader(\n",
    "    'grape_detection_californiaday', \n",
    "    dataset_path='../datasets/grape_detection_californiaday'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 75/75 [00:01<00:00, 68.58it/s]\n",
      "Processing val: 100%|██████████| 18/18 [00:00<00:00, 104.10it/s]\n",
      "Processing test: 100%|██████████| 33/33 [00:00<00:00, 97.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion and splitting completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coco_to_yolo(\n",
    "    coco_json_path=\"../datasets/grape_detection_californiaday/annotations.json\", \n",
    "    images_dir=\"../datasets/grape_detection_californiaday/images\",\n",
    "    output_dir=\"../datasets/grape_detection_californiaday/reformatted\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
