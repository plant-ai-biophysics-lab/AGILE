{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning as L\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, hidden_dim: int = 64, learning_rate=10e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, batch_idx, \"test\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        x = self._prepare_batch(batch)\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def _prepare_batch(self, batch):\n",
    "        x, _ = batch\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def _common_step(self, batch, batch_idx, stage: str):\n",
    "        x = self._prepare_batch(batch)\n",
    "        loss = F.mse_loss(x, self(x))\n",
    "        self.log(f\"{stage}_loss\", loss, on_step=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset\n",
    "root_dir = '/data2/eranario/data/MNIST-Dataset/lightning'\n",
    "transform = transforms.ToTensor()\n",
    "train_set = MNIST(root_dir, download=False, train=True, transform=transform)\n",
    "test_set = MNIST(root_dir, download=False, train=False, transform=transform)\n",
    "\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set_split, valid_set_split = data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "train_loader_full = DataLoader(train_set, batch_size=10, shuffle=False)\n",
    "train_loader_split = DataLoader(train_set_split, batch_size=10, shuffle=False)\n",
    "valid_loader = DataLoader(valid_set_split, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/eranario/miniconda3/envs/lightning/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K\n",
      "1 | decoder | Sequential | 51.2 K\n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/home/eranario/miniconda3/envs/lightning/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 100/100 [00:00<00:00, 127.17it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 100/100 [00:00<00:00, 125.49it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=50, default_root_dir=\"/data2/eranario/intermediate_data/MNIST_logs/setup\")\n",
    "# trainer.fit(autoencoder, train_loader, valid_loader)\n",
    "trainer.fit(autoencoder, train_loader_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eranario/miniconda3/envs/lightning/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 10000/10000 [00:20<00:00, 487.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint\n",
    "checkpoint = \"/data2/eranario/intermediate_data/MNIST_logs/setup/lightning_logs/version_1/checkpoints/epoch=49-step=5000.ckpt\"\n",
    "test_loader = DataLoader(test_set)\n",
    "autoencoder = LitAutoEncoder.load_from_checkpoint(checkpoint)\n",
    "\n",
    "# run predictions\n",
    "predictions = trainer.predict(autoencoder, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.cat(predictions).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, _ = next(iter(test_loader))\n",
    "num_images = min(10, len(inputs))  # Adjust the number based on the actual batch size\n",
    "\n",
    "fig, axes = plt.subplots(2, num_images, figsize=(2 * num_images, 4))  # 2 rows, num_images columns\n",
    "\n",
    "# Check if axes is a 1D array and make it 2D if necessary\n",
    "if num_images == 1:\n",
    "    axes = axes.reshape(2, -1)  # Reshape to 2D (2 rows, 1 column)\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Reshape and display the input images\n",
    "    input_img = inputs[i].view(28, 28).numpy()  # Ensure inputs are reshaped to 28x28 for display\n",
    "    axes[0, i].imshow(input_img, cmap='gray')\n",
    "    axes[0, i].axis('off')  # Turn off axis numbering\n",
    "    axes[0, i].set_title(f'Input {i+1}')\n",
    "\n",
    "    # Reshape and display the predicted images\n",
    "    pred_img = predictions[i].view(28, 28).numpy()\n",
    "    axes[1, i].imshow(pred_img, cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    axes[1, i].set_title(f'Prediction {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
